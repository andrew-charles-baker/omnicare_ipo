---
title: "Validating the Fact-Intensity Measure"
author: "Research Team"
date: today
format:
  html:
    toc: true
    code-fold: true
    fig-width: 8
    fig-height: 6
---

## Overview

This document validates the BERT-based fact-intensity measure (`rf_fact_t07`) by examining its relationship with first-day IPO returns. The hypothesis is:

> **Higher fact-intensity in S-1 risk factor disclosures should be associated with lower first-day returns** (less underpricing).

The intuition is that more factual disclosure reduces information asymmetry between issuers and investors, leading to more accurate pricing and smaller first-day "pops."

We examine this relationship using three approaches:

1. **Linear Regression**: OLS of first-day return on fact-intensity
2. **Binscatter**: Non-parametric visualization using optimal binning (Cattaneo et al.)
3. **Distribution Regression**: Series of binary regressions at different return thresholds

Each analysis is conducted for:

- Full sample
- Pre-Omnicare (before March 24, 2015)
- Post-Omnicare (March 24, 2015 and after)

**Sample Restriction**: We restrict the sample to IPOs with an offer price ≥ $5 to exclude penny stocks and very small offerings that may exhibit extreme volatility unrelated to disclosure quality.

```{r}
#| label: setup
#| message: false
#| warning: false

library(ggplot2)

# Load data
df_raw <- read.csv("../data/omnicare_rf.csv")
df <- df_raw[df_raw$offer_price >= 5, ]  # Restrict to offer price >= $5

# Create post-Omnicare indicator
df$post_omnicare <- as.Date(df$offer_date) >= as.Date("2015-03-24")
df$period <- ifelse(df$post_omnicare, "Post-Omnicare", "Pre-Omnicare")

# ============================================================================
# Fama-French 12 Industry Classification
# Source: Kenneth French Data Library
# https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_12_ind_port.html
# ============================================================================

assign_ff12 <- function(sic) {
  # Returns Fama-French 12 industry classification based on SIC code
  # Returns NA if SIC is missing

  if (is.na(sic)) return(NA_character_)
  sic <- as.integer(sic)

  # 1. Consumer NonDurables
  if ((sic >= 100 & sic <= 999) |
      (sic >= 2000 & sic <= 2399) |
      (sic >= 2700 & sic <= 2749) |
      (sic >= 2770 & sic <= 2799) |
      (sic >= 3100 & sic <= 3199) |
      (sic >= 3940 & sic <= 3989)) {
    return("NoDur")
  }

  # 2. Consumer Durables
  if ((sic >= 2500 & sic <= 2519) |
      (sic >= 2590 & sic <= 2599) |
      (sic >= 3630 & sic <= 3659) |
      (sic >= 3710 & sic <= 3711) |
      (sic == 3714) |
      (sic == 3716) |
      (sic >= 3750 & sic <= 3751) |
      (sic == 3792) |
      (sic >= 3900 & sic <= 3939) |
      (sic >= 3990 & sic <= 3999)) {
    return("Durbl")
  }

  # 3. Manufacturing
  if ((sic >= 2520 & sic <= 2589) |
      (sic >= 2600 & sic <= 2699) |
      (sic >= 2750 & sic <= 2769) |
      (sic >= 3000 & sic <= 3099) |
      (sic >= 3200 & sic <= 3569) |
      (sic >= 3580 & sic <= 3629) |
      (sic >= 3700 & sic <= 3709) |
      (sic >= 3712 & sic <= 3713) |
      (sic == 3715) |
      (sic >= 3717 & sic <= 3749) |
      (sic >= 3752 & sic <= 3791) |
      (sic >= 3793 & sic <= 3799) |
      (sic >= 3830 & sic <= 3839) |
      (sic >= 3860 & sic <= 3899)) {
    return("Manuf")
  }

  # 4. Energy (Oil, Gas, Coal)
  if ((sic >= 1200 & sic <= 1399) |
      (sic >= 2900 & sic <= 2999)) {
    return("Enrgy")
  }

  # 5. Chemicals
  if ((sic >= 2800 & sic <= 2829) |
      (sic >= 2840 & sic <= 2899)) {
    return("Chems")
  }

  # 6. Business Equipment (Computers, Software, Electronics)
  if ((sic >= 3570 & sic <= 3579) |
      (sic >= 3660 & sic <= 3692) |
      (sic >= 3694 & sic <= 3699) |
      (sic >= 3810 & sic <= 3829) |
      (sic >= 7370 & sic <= 7379)) {
    return("BusEq")
  }

  # 7. Telecommunications
  if (sic >= 4800 & sic <= 4899) {
    return("Telcm")
  }

  # 8. Utilities
  if (sic >= 4900 & sic <= 4949) {
    return("Utils")
  }

  # 9. Wholesale/Retail (Shops)
  if ((sic >= 5000 & sic <= 5999) |
      (sic >= 7200 & sic <= 7299) |
      (sic >= 7600 & sic <= 7699)) {
    return("Shops")
  }

  # 10. Healthcare (Medical Equipment, Drugs)
  if ((sic >= 2830 & sic <= 2839) |
      (sic == 3693) |
      (sic >= 3840 & sic <= 3859) |
      (sic >= 8000 & sic <= 8099)) {
    return("Hlth")
  }

  # 11. Finance
  if (sic >= 6000 & sic <= 6999) {
    return("Money")
  }

  # 12. Other
  return("Other")
}

# Apply FF12 classification
df$ff12 <- sapply(df$sic_code, assign_ff12)
df$ff12 <- factor(df$ff12, levels = c("NoDur", "Durbl", "Manuf", "Enrgy", "Chems",
                                       "BusEq", "Telcm", "Utils", "Shops", "Hlth",
                                       "Money", "Other"))

# Log-transform size variables (adding small constant to avoid log(0))
df$log_assets <- log(df$assets_thous + 1)
df$log_proceeds <- log(df$total_proceeds_thous + 1)

# Sample sizes
cat("Sample restriction: offer_price >= $5\n")
cat("Original sample:", nrow(df_raw), "| Restricted sample:", nrow(df), "\n\n")
cat("Full sample:", nrow(df), "\n")
cat("Pre-Omnicare:", sum(!df$post_omnicare), "\n")
cat("Post-Omnicare:", sum(df$post_omnicare), "\n")

cat("\n=== Fama-French 12 Industry Distribution ===\n")
print(table(df$ff12, useNA = "ifany"))
```

---

## 1. Linear Regression

We estimate:
$$\text{FirstDayReturn}_i = \alpha + \beta \cdot \text{rf\_fact\_t07}_i + \varepsilon_i$$

A negative $\beta$ would support the hypothesis that higher fact-intensity is associated with lower underpricing.

### Full Sample

```{r}
#| label: ols-full

model_full <- lm(first_day_return ~ rf_fact_t07, data = df)
summary(model_full)
```

### Pre-Omnicare

```{r}
#| label: ols-pre

model_pre <- lm(first_day_return ~ rf_fact_t07, data = df[!df$post_omnicare, ])
summary(model_pre)
```

### Post-Omnicare

```{r}
#| label: ols-post

model_post <- lm(first_day_return ~ rf_fact_t07, data = df[df$post_omnicare, ])
summary(model_post)
```

### Summary Table

```{r}
#| label: ols-summary

ols_results <- data.frame(
  Sample = c("Full Sample", "Pre-Omnicare", "Post-Omnicare"),
  N = c(nrow(df), sum(!df$post_omnicare), sum(df$post_omnicare)),
  Coefficient = c(coef(model_full)[2], coef(model_pre)[2], coef(model_post)[2]),
  Std_Error = c(summary(model_full)$coefficients[2, 2],
                summary(model_pre)$coefficients[2, 2],
                summary(model_post)$coefficients[2, 2]),
  t_stat = c(summary(model_full)$coefficients[2, 3],
             summary(model_pre)$coefficients[2, 3],
             summary(model_post)$coefficients[2, 3]),
  p_value = c(summary(model_full)$coefficients[2, 4],
              summary(model_pre)$coefficients[2, 4],
              summary(model_post)$coefficients[2, 4]),
  R_squared = c(summary(model_full)$r.squared,
                summary(model_pre)$r.squared,
                summary(model_post)$r.squared)
)

knitr::kable(ols_results, digits = 4,
             col.names = c("Sample", "N", "Coefficient", "Std. Error", "t-stat", "p-value", "R²"))
```

---

## 2. Binscatter (Optimal Binning)

Binscatter provides a non-parametric visualization of the conditional expectation function.

**Note on Implementation**: For IMSE-optimal binning, install the [`binsreg`](https://nppackages.github.io/binsreg/) package from Cattaneo, Crump, Farrell, and Feng (2024). The implementation below uses a simplified quantile-based approach with the number of bins set via the rule-of-thumb $J \approx \lceil n^{1/3} \rceil$.

```{r}
#| label: binscatter-function

# Check if binsreg is available; if not, use quantile-based fallback
use_binsreg <- requireNamespace("binsreg", quietly = TRUE)

if (use_binsreg) {
  cat("Using binsreg package for IMSE-optimal binning\n")
} else {
  cat("binsreg not available; using quantile-based binning (ROT: n^(1/3) bins)\n")
}

# Binscatter function with binsreg or fallback
binscatter <- function(data, x_var, y_var, n_bins = NULL, title = "") {

  x <- data[[x_var]]
  y <- data[[y_var]]

  # Remove missing values
  complete <- complete.cases(x, y)
  x <- x[complete]
  y <- y[complete]
  n <- length(x)

  # If binsreg available, use it
  if (use_binsreg) {
    library(binsreg)
    result <- binsreg(y, x, line = c(3, 3), cb = c(3, 3))
    return(list(plot = result$bins_plot, binsreg_output = result))
  }

  # Fallback: Rule-of-thumb number of bins (Cattaneo et al. suggest n^(1/3))
  if (is.null(n_bins)) {
    n_bins <- ceiling(n^(1/3))
  }

  # Create quantile-based bins
  breaks <- quantile(x, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE)
  breaks <- unique(breaks)  # Handle ties
  bins <- cut(x, breaks = breaks, include.lowest = TRUE, labels = FALSE)

  # Compute bin means
  bin_means <- aggregate(
    cbind(x_mean = x, y_mean = y),
    by = list(bin = bins),
    FUN = mean,
    na.rm = TRUE
  )

  # Linear fit for overlay
  fit <- lm(y ~ x)

  # Create plot
  p <- ggplot() +
    geom_point(data = bin_means, aes(x = x_mean, y = y_mean),
               size = 3, color = "steelblue") +
    geom_abline(intercept = coef(fit)[1], slope = coef(fit)[2],
                color = "darkred", linewidth = 1, linetype = "dashed") +
    labs(
      title = title,
      subtitle = paste0("N = ", n, " | Bins = ", length(unique(bins)),
                        " (ROT: n^1/3) | Slope = ", round(coef(fit)[2], 4)),
      x = "Fact-Intensity (rf_fact_t07)",
      y = "First-Day Return"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 10, color = "gray40")
    )

  return(list(plot = p, bin_data = bin_means, fit = fit))
}
```

### Full Sample

```{r}
#| label: binscatter-full
#| fig-cap: "Binscatter: Fact-Intensity vs First-Day Return (Full Sample)"

bs_full <- binscatter(df, "rf_fact_t07", "first_day_return",
                      title = "Full Sample")
print(bs_full$plot)
```

### Pre-Omnicare

```{r}
#| label: binscatter-pre
#| fig-cap: "Binscatter: Fact-Intensity vs First-Day Return (Pre-Omnicare)"

bs_pre <- binscatter(df[!df$post_omnicare, ], "rf_fact_t07", "first_day_return",
                     title = "Pre-Omnicare (before March 24, 2015)")
print(bs_pre$plot)
```

### Post-Omnicare

```{r}
#| label: binscatter-post
#| fig-cap: "Binscatter: Fact-Intensity vs First-Day Return (Post-Omnicare)"

bs_post <- binscatter(df[df$post_omnicare, ], "rf_fact_t07", "first_day_return",
                      title = "Post-Omnicare (March 24, 2015 and after)")
print(bs_post$plot)
```

### Combined Panel

```{r}
#| label: binscatter-combined
#| fig-cap: "Binscatter by Period"
#| fig-height: 5

# Create binned data for both periods (using ROT: n^(1/3) bins)
create_bin_data <- function(data) {
  x <- data$rf_fact_t07
  y <- data$first_day_return
  n_bins <- ceiling(length(x)^(1/3))  # ROT from Cattaneo et al.
  breaks <- quantile(x, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE)
  breaks <- unique(breaks)
  bins <- cut(x, breaks = breaks, include.lowest = TRUE, labels = FALSE)
  bin_means <- aggregate(
    cbind(x_mean = x, y_mean = y),
    by = list(bin = bins),
    FUN = mean, na.rm = TRUE
  )
  return(bin_means)
}

bin_pre <- create_bin_data(df[!df$post_omnicare, ])
bin_pre$period <- "Pre-Omnicare"
bin_post <- create_bin_data(df[df$post_omnicare, ])
bin_post$period <- "Post-Omnicare"
bin_combined <- rbind(bin_pre, bin_post)

ggplot(bin_combined, aes(x = x_mean, y = y_mean, color = period)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  labs(
    title = "Binscatter: Fact-Intensity vs First-Day Return by Period",
    x = "Fact-Intensity (rf_fact_t07)",
    y = "First-Day Return",
    color = "Period"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )
```

---

## 3. Distribution Regression

Distribution regression estimates the effect of fact-intensity on the probability of exceeding various return thresholds. This provides a more complete picture of how fact-intensity shifts the entire distribution of returns, not just the mean.

For each threshold $\tau$, we estimate a logistic regression:
$$P(\text{FirstDayReturn}_i > \tau) = \Lambda(\alpha_\tau + \beta_\tau \cdot \text{rf\_fact\_t07}_i)$$

where $\Lambda(\cdot)$ is the logistic CDF. We report **marginal effects** evaluated at the sample mean:
$$\frac{\partial P(Y > \tau | X = \bar{x})}{\partial x} = \beta_\tau \cdot \Lambda(\alpha_\tau + \beta_\tau \bar{x}) \cdot (1 - \Lambda(\alpha_\tau + \beta_\tau \bar{x}))$$

If higher fact-intensity reduces returns, we expect negative marginal effects (lower probability of exceeding any given threshold).

```{r}
#| label: distribution-regression-function

# Distribution regression: series of binary regressions with marginal effects
distribution_regression <- function(data, x_var, y_var,
                                    thresholds = NULL, n_thresholds = 20,
                                    n_bootstrap = 200) {

  x <- data[[x_var]]
  y <- data[[y_var]]

  # Remove missing values
  complete <- complete.cases(x, y)
  x <- x[complete]
  y <- y[complete]
  n <- length(x)

  # Evaluation point: sample mean of x
  x_mean <- mean(x, na.rm = TRUE)

  # Default thresholds: quantiles of y
  if (is.null(thresholds)) {
    thresholds <- quantile(y, probs = seq(0.05, 0.95, length.out = n_thresholds), na.rm = TRUE)
    thresholds <- unique(thresholds)
  }

  results <- data.frame(
    threshold = numeric(),
    coefficient = numeric(),
    marginal_effect = numeric(),
    me_lower = numeric(),
    me_upper = numeric(),
    prop_above = numeric()
  )

  for (tau in thresholds) {
    # Binary outcome: 1 if y > tau
    y_binary <- as.integer(y > tau)

    # Skip if all same value
    if (length(unique(y_binary)) < 2) next

    # Logistic regression
    model <- glm(y_binary ~ x, family = binomial(link = "logit"))
    coefs <- coef(model)

    if (any(is.na(coefs)) || length(coefs) < 2) next

    # Marginal effect at sample mean: β * λ(Xβ) * (1 - λ(Xβ))
    linear_pred <- coefs[1] + coefs[2] * x_mean
    lambda_val <- plogis(linear_pred)
    marginal_effect <- coefs[2] * lambda_val * (1 - lambda_val)

    # Bootstrap for confidence intervals
    boot_me <- numeric(n_bootstrap)
    for (b in 1:n_bootstrap) {
      # Weighted bootstrap (exponential weights)
      weights <- rexp(n, rate = 1)

      tryCatch({
        boot_fit <- glm(y_binary ~ x, family = binomial(link = "logit"), weights = weights)
        boot_coefs <- coef(boot_fit)
        if (!any(is.na(boot_coefs)) && length(boot_coefs) >= 2) {
          boot_lp <- boot_coefs[1] + boot_coefs[2] * x_mean
          boot_lambda <- plogis(boot_lp)
          boot_me[b] <- boot_coefs[2] * boot_lambda * (1 - boot_lambda)
        } else {
          boot_me[b] <- NA
        }
      }, error = function(e) {
        boot_me[b] <- NA
      })
    }

    # Calculate bootstrap CI
    boot_me_clean <- boot_me[!is.na(boot_me)]
    if (length(boot_me_clean) > 10) {
      me_lower <- quantile(boot_me_clean, 0.025)
      me_upper <- quantile(boot_me_clean, 0.975)
    } else {
      me_lower <- NA
      me_upper <- NA
    }

    results <- rbind(results, data.frame(
      threshold = tau,
      coefficient = coefs[2],
      marginal_effect = marginal_effect,
      me_lower = me_lower,
      me_upper = me_upper,
      prop_above = mean(y_binary, na.rm = TRUE)
    ))
  }

  return(results)
}
```

### Full Sample

```{r}
#| label: dist-reg-full
#| fig-cap: "Distribution Regression Marginal Effects (Full Sample)"
#| warning: false

dr_full <- distribution_regression(df, "rf_fact_t07", "first_day_return", n_thresholds = 25)

ggplot(dr_full, aes(x = threshold, y = marginal_effect)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper),
              alpha = 0.2, fill = "steelblue") +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "steelblue", size = 2) +
  labs(
    title = "Distribution Regression: Marginal Effects of Fact-Intensity",
    subtitle = "Full Sample | Change in P(Return > threshold) per unit increase in rf_fact, evaluated at sample mean",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### Pre-Omnicare

```{r}
#| label: dist-reg-pre
#| fig-cap: "Distribution Regression Marginal Effects (Pre-Omnicare)"
#| warning: false

dr_pre <- distribution_regression(df[!df$post_omnicare, ], "rf_fact_t07", "first_day_return",
                                  n_thresholds = 20)

ggplot(dr_pre, aes(x = threshold, y = marginal_effect)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper),
              alpha = 0.2, fill = "coral") +
  geom_line(color = "coral", linewidth = 1) +
  geom_point(color = "coral", size = 2) +
  labs(
    title = "Distribution Regression: Pre-Omnicare",
    subtitle = "Before March 24, 2015 | Marginal effects evaluated at sample mean",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### Post-Omnicare

```{r}
#| label: dist-reg-post
#| fig-cap: "Distribution Regression Marginal Effects (Post-Omnicare)"
#| warning: false

dr_post <- distribution_regression(df[df$post_omnicare, ], "rf_fact_t07", "first_day_return",
                                   n_thresholds = 25)

ggplot(dr_post, aes(x = threshold, y = marginal_effect)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper),
              alpha = 0.2, fill = "steelblue") +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "steelblue", size = 2) +
  labs(
    title = "Distribution Regression: Post-Omnicare",
    subtitle = "March 24, 2015 and after | Marginal effects evaluated at sample mean",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### Combined Comparison

```{r}
#| label: dist-reg-combined
#| fig-cap: "Distribution Regression Marginal Effects by Period"

dr_pre$period <- "Pre-Omnicare"
dr_post$period <- "Post-Omnicare"
dr_combined <- rbind(dr_pre, dr_post)

ggplot(dr_combined, aes(x = threshold, y = marginal_effect, color = period, fill = period)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper),
              alpha = 0.15, color = NA) +
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  scale_fill_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  labs(
    title = "Distribution Regression: Pre vs Post-Omnicare",
    subtitle = "Marginal effects with bootstrap 95% CIs",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact",
    color = "Period",
    fill = "Period"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )
```

---

## 4. Summary and Interpretation

```{r}
#| label: summary-interpretation

cat("=== LINEAR REGRESSION SUMMARY ===\n\n")
for (i in 1:nrow(ols_results)) {
  sign <- ifelse(ols_results$Coefficient[i] < 0, "NEGATIVE", "POSITIVE")
  sig <- ifelse(ols_results$p_value[i] < 0.05, "(significant at 5%)", "(not significant at 5%)")
  cat(sprintf("%s: beta = %.4f %s\n",
              ols_results$Sample[i], ols_results$Coefficient[i], sig))
}

cat("\n=== INTERPRETATION ===\n\n")

# Check if hypothesis is supported
full_coef <- coef(model_full)[2]
if (full_coef < 0) {
  cat("The hypothesis is SUPPORTED in the full sample:\n")
  cat("Higher fact-intensity is associated with LOWER first-day returns.\n")
  cat(sprintf("A one-unit increase in rf_fact_t07 is associated with a %.1f percentage point\n",
              abs(full_coef) * 100))
  cat("decrease in first-day returns.\n")
} else {
  cat("The hypothesis is NOT SUPPORTED in the full sample:\n")
  cat("Higher fact-intensity is associated with HIGHER first-day returns.\n")
  cat("This is contrary to the information asymmetry hypothesis.\n")
}
```

---

## Technical Notes

### Binscatter Method

The binscatter implementation uses quantile-based binning with the rule-of-thumb (ROT) number of bins $J \approx \lceil n^{1/3} \rceil$. For proper IMSE-optimal binning with data-driven bin selection, confidence bands, and polynomial smoothing, install the [`binsreg`](https://nppackages.github.io/binsreg/) package:

```r
install.packages("binsreg")
```

Reference: Cattaneo, M. D., Crump, R. K., Farrell, M. H., & Feng, Y. (2024). "On Binscatter." *American Economic Review*, 114(5), 1488-1514.

### Distribution Regression

Distribution regression estimates the conditional distribution function at various thresholds, providing insight into heterogeneous effects across the return distribution. We use logit link functions (logistic regression) at each threshold.

We report **marginal effects** rather than raw logit coefficients. The marginal effect is:
$$\frac{\partial P(Y > \tau | X = \bar{x})}{\partial x} = \beta \cdot \Lambda(\alpha + \beta \bar{x}) \cdot (1 - \Lambda(\alpha + \beta \bar{x}))$$

evaluated at the sample mean of rf_fact_t07. This gives the actual change in probability (not log-odds) for a one-unit increase in fact-intensity. Bootstrap confidence intervals (200 replications) are computed using weighted bootstrap with exponential weights.

Reference: Chernozhukov, V., Fernández-Val, I., & Melly, B. (2013). "Inference on Counterfactual Distributions." *Econometrica*, 81(6), 2205-2268.

---

## 5. Covariate-Controlled Analysis

This section augments the baseline analysis by controlling for observable firm characteristics:

- **Log Assets** (`log_assets`): Natural log of total assets (in thousands)
- **Log Total Proceeds** (`log_proceeds`): Natural log of total IPO proceeds (in thousands)
- **Industry Fixed Effects** (`ff12`): Fama-French 12 industry classification based on SIC codes
- **Rolling Market Return** (`roll_vwretd`): Value-weighted market return in the 30 days prior to IPO

These controls help isolate the relationship between fact-intensity and first-day returns from confounding factors related to firm size, deal size, industry characteristics, and market conditions.

### 5.1 OLS with Controls

```{r}
#| label: ols-controls
#| message: false

# Check for missing values in control variables
cat("=== Missing Values in Control Variables ===\n")
cat("log_assets:", sum(is.na(df$log_assets)), "\n")
cat("log_proceeds:", sum(is.na(df$log_proceeds)), "\n")
cat("roll_vwretd:", sum(is.na(df$roll_vwretd)), "\n")
cat("ff12:", sum(is.na(df$ff12)), "\n")

# Complete cases for covariate analysis
df_complete <- df[complete.cases(df[, c("first_day_return", "rf_fact_t07",
                                         "log_assets", "log_proceeds",
                                         "roll_vwretd", "ff12")]), ]
cat("\nObservations with complete covariate data:", nrow(df_complete), "\n")

# Full sample with controls
model_full_ctrl <- lm(first_day_return ~ rf_fact_t07 + log_assets + log_proceeds +
                        roll_vwretd + ff12, data = df_complete)

# Pre-Omnicare with controls
model_pre_ctrl <- lm(first_day_return ~ rf_fact_t07 + log_assets + log_proceeds +
                       roll_vwretd + ff12, data = df_complete[!df_complete$post_omnicare, ])

# Post-Omnicare with controls
model_post_ctrl <- lm(first_day_return ~ rf_fact_t07 + log_assets + log_proceeds +
                        roll_vwretd + ff12, data = df_complete[df_complete$post_omnicare, ])

cat("\n=== FULL SAMPLE (with controls) ===\n")
summary(model_full_ctrl)
```

### Comparison: Baseline vs. Controlled

```{r}
#| label: ols-comparison

# Extract rf_fact_t07 coefficients
extract_rf_coef <- function(model) {
  coefs <- summary(model)$coefficients
  if ("rf_fact_t07" %in% rownames(coefs)) {
    return(c(coef = coefs["rf_fact_t07", 1],
             se = coefs["rf_fact_t07", 2],
             t = coefs["rf_fact_t07", 3],
             p = coefs["rf_fact_t07", 4]))
  }
  return(c(coef = NA, se = NA, t = NA, p = NA))
}

comparison <- data.frame(
  Sample = rep(c("Full Sample", "Pre-Omnicare", "Post-Omnicare"), 2),
  Specification = c(rep("Baseline", 3), rep("With Controls", 3)),
  Coefficient = c(
    coef(model_full)[2], coef(model_pre)[2], coef(model_post)[2],
    extract_rf_coef(model_full_ctrl)["coef"],
    extract_rf_coef(model_pre_ctrl)["coef"],
    extract_rf_coef(model_post_ctrl)["coef"]
  ),
  Std_Error = c(
    summary(model_full)$coefficients[2, 2],
    summary(model_pre)$coefficients[2, 2],
    summary(model_post)$coefficients[2, 2],
    extract_rf_coef(model_full_ctrl)["se"],
    extract_rf_coef(model_pre_ctrl)["se"],
    extract_rf_coef(model_post_ctrl)["se"]
  ),
  p_value = c(
    summary(model_full)$coefficients[2, 4],
    summary(model_pre)$coefficients[2, 4],
    summary(model_post)$coefficients[2, 4],
    extract_rf_coef(model_full_ctrl)["p"],
    extract_rf_coef(model_pre_ctrl)["p"],
    extract_rf_coef(model_post_ctrl)["p"]
  )
)

knitr::kable(comparison, digits = 4,
             caption = "Effect of Fact-Intensity on First-Day Returns: Baseline vs. Controlled",
             col.names = c("Sample", "Specification", "Coefficient", "Std. Error", "p-value"))
```

### Control Variable Effects

```{r}
#| label: control-effects

cat("=== CONTROL VARIABLE COEFFICIENTS (Full Sample) ===\n\n")
coef_table <- summary(model_full_ctrl)$coefficients
print(round(coef_table, 4))

cat("\n=== INTERPRETATION OF CONTROLS ===\n")
cat("\nlog_assets: Larger firms by assets tend to have",
    ifelse(coef(model_full_ctrl)["log_assets"] < 0, "LOWER", "HIGHER"),
    "first-day returns\n")
cat("log_proceeds: Larger deals tend to have",
    ifelse(coef(model_full_ctrl)["log_proceeds"] < 0, "LOWER", "HIGHER"),
    "first-day returns\n")
cat("roll_vwretd: Hot markets (higher prior returns) are associated with",
    ifelse(coef(model_full_ctrl)["roll_vwretd"] < 0, "LOWER", "HIGHER"),
    "first-day returns\n")
```

### 5.2 Binscatter with Controls

To visualize the partial relationship between fact-intensity and first-day returns after controlling for covariates, we use the Frisch-Waugh-Lovell approach. The `binsreg` package handles this automatically via the `w` parameter for covariates.

```{r}
#| label: binscatter-controls
#| fig-cap: "Binscatter with Controls (Full Sample)"

# Prepare control matrix for binsreg (excluding the factor, which we'll handle)
W_matrix <- model.matrix(~ log_assets + log_proceeds + roll_vwretd + ff12,
                          data = df_complete)[, -1]  # Remove intercept

if (use_binsreg) {
  # Use binsreg with covariates
  library(binsreg)
  bs_ctrl_result <- binsreg(
    y = df_complete$first_day_return,
    x = df_complete$rf_fact_t07,
    w = W_matrix,
    line = c(3, 3),
    ci = c(3, 3)
  )
  print(bs_ctrl_result$bins_plot +
          labs(title = "Binscatter with Controls (Full Sample)",
               subtitle = "IMSE-optimal binning | Controlling for log(assets), log(proceeds), roll_vwretd, FF12",
               x = "Fact-Intensity (rf_fact_t07)",
               y = "First-Day Return (residualized)"))

} else {
  # Fallback: Manual FWL residualization
  resid_y_model <- lm(first_day_return ~ log_assets + log_proceeds + roll_vwretd + ff12,
                       data = df_complete)
  resid_x_model <- lm(rf_fact_t07 ~ log_assets + log_proceeds + roll_vwretd + ff12,
                       data = df_complete)

  df_complete$resid_y <- residuals(resid_y_model)
  df_complete$resid_x <- residuals(resid_x_model)

  # Binscatter on residualized data
  x <- df_complete$resid_x
  y <- df_complete$resid_y
  n <- length(x)
  n_bins <- ceiling(n^(1/3))

  breaks <- quantile(x, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE)
  breaks <- unique(breaks)
  bins <- cut(x, breaks = breaks, include.lowest = TRUE, labels = FALSE)

  bin_means <- aggregate(
    cbind(x_mean = x, y_mean = y),
    by = list(bin = bins),
    FUN = mean, na.rm = TRUE
  )

  fit <- lm(y ~ x)

  p <- ggplot() +
    geom_point(data = bin_means, aes(x = x_mean, y = y_mean),
               size = 3, color = "darkgreen") +
    geom_abline(intercept = coef(fit)[1], slope = coef(fit)[2],
                color = "darkgreen", linewidth = 1, linetype = "dashed") +
    labs(
      title = "Binscatter with Controls (Full Sample)",
      subtitle = paste0("N = ", n, " | Bins = ", length(unique(bins)),
                        " | Slope = ", round(coef(fit)[2], 4),
                        " | FWL residualization"),
      x = "Residualized Fact-Intensity",
      y = "Residualized First-Day Return"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 10, color = "gray40")
    )

  print(p)
}

cat("\nOLS coefficient on rf_fact_t07 (with controls):",
    round(coef(model_full_ctrl)["rf_fact_t07"], 4), "\n")
```

### Binscatter by Period (with Controls)

```{r}
#| label: binscatter-controls-periods
#| fig-cap: "Binscatter with Controls by Period"
#| fig-height: 5

# Split data by period
df_pre <- df_complete[!df_complete$post_omnicare, ]
df_post <- df_complete[df_complete$post_omnicare, ]

if (use_binsreg) {
  # Use binsreg with covariates for each period
  library(binsreg)

  # Control matrices for each period
  W_pre <- model.matrix(~ log_assets + log_proceeds + roll_vwretd + ff12,
                         data = df_pre)[, -1]
  W_post <- model.matrix(~ log_assets + log_proceeds + roll_vwretd + ff12,
                          data = df_post)[, -1]

  # Pre-Omnicare
  bs_pre_ctrl <- binsreg(
    y = df_pre$first_day_return,
    x = df_pre$rf_fact_t07,
    w = W_pre,
    line = c(3, 3)
  )

  # Post-Omnicare
  bs_post_ctrl <- binsreg(
    y = df_post$first_day_return,
    x = df_post$rf_fact_t07,
    w = W_post,
    line = c(3, 3)
  )

  # Extract bin data and combine
  pre_data <- bs_pre_ctrl$data.plot$`Group Full Sample`$data.dots
  pre_data$period <- "Pre-Omnicare"
  post_data <- bs_post_ctrl$data.plot$`Group Full Sample`$data.dots
  post_data$period <- "Post-Omnicare"
  combined_data <- rbind(pre_data, post_data)

  # Get slopes from OLS with controls
  slope_pre <- coef(model_pre_ctrl)["rf_fact_t07"]
  slope_post <- coef(model_post_ctrl)["rf_fact_t07"]

  ggplot(combined_data, aes(x = x, y = fit, color = period)) +
    geom_point(size = 3) +
    geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
    scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
    labs(
      title = "Binscatter with Controls: Pre vs. Post-Omnicare",
      subtitle = sprintf("OLS slopes (with controls): Pre = %.4f | Post = %.4f", slope_pre, slope_post),
      x = "Fact-Intensity (rf_fact_t07)",
      y = "First-Day Return (residualized)",
      color = "Period"
    ) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      plot.title = element_text(face = "bold")
    )

} else {
  # Fallback: Manual FWL residualization
  resid_y_pre <- lm(first_day_return ~ log_assets + log_proceeds + roll_vwretd + ff12,
                     data = df_pre)
  resid_x_pre <- lm(rf_fact_t07 ~ log_assets + log_proceeds + roll_vwretd + ff12,
                     data = df_pre)
  df_pre$resid_y <- residuals(resid_y_pre)
  df_pre$resid_x <- residuals(resid_x_pre)

  resid_y_post <- lm(first_day_return ~ log_assets + log_proceeds + roll_vwretd + ff12,
                      data = df_post)
  resid_x_post <- lm(rf_fact_t07 ~ log_assets + log_proceeds + roll_vwretd + ff12,
                      data = df_post)
  df_post$resid_y <- residuals(resid_y_post)
  df_post$resid_x <- residuals(resid_x_post)

  # Create binned data for both periods
  create_resid_bins <- function(data) {
    x <- data$resid_x
    y <- data$resid_y
    n_bins <- ceiling(length(x)^(1/3))
    breaks <- quantile(x, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE)
    breaks <- unique(breaks)
    bins <- cut(x, breaks = breaks, include.lowest = TRUE, labels = FALSE)
    bin_means <- aggregate(
      cbind(x_mean = x, y_mean = y),
      by = list(bin = bins),
      FUN = mean, na.rm = TRUE
    )
    return(bin_means)
  }

  bin_pre_ctrl <- create_resid_bins(df_pre)
  bin_pre_ctrl$period <- "Pre-Omnicare"
  bin_post_ctrl <- create_resid_bins(df_post)
  bin_post_ctrl$period <- "Post-Omnicare"
  bin_combined_ctrl <- rbind(bin_pre_ctrl, bin_post_ctrl)

  # Get slopes for annotation
  slope_pre <- coef(lm(resid_y ~ resid_x, data = df_pre))[2]
  slope_post <- coef(lm(resid_y ~ resid_x, data = df_post))[2]

  ggplot(bin_combined_ctrl, aes(x = x_mean, y = y_mean, color = period)) +
    geom_point(size = 3) +
    geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
    scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
    labs(
      title = "Binscatter with Controls: Pre vs. Post-Omnicare",
      subtitle = sprintf("Slopes: Pre = %.4f | Post = %.4f", slope_pre, slope_post),
      x = "Residualized Fact-Intensity",
      y = "Residualized First-Day Return",
      color = "Period"
    ) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      plot.title = element_text(face = "bold")
    )
}
```

### 5.3 Distribution Regression with Controls

We extend the distribution regression to include covariates. For each threshold $\tau$, we estimate:

$$P(\text{FirstDayReturn}_i > \tau) = \Lambda(\alpha_\tau + \beta_\tau \cdot \text{rf\_fact\_t07}_i + \gamma_\tau' \mathbf{X}_i)$$

where $\mathbf{X}_i$ includes log assets, log proceeds, rolling market return, and industry fixed effects.

```{r}
#| label: dist-reg-controls-function

# Distribution regression with controls
distribution_regression_controls <- function(data, x_var, y_var, controls,
                                              thresholds = NULL, n_thresholds = 20,
                                              n_bootstrap = 200) {

  # Build formula
  formula_str <- paste("y_binary ~", x_var, "+", paste(controls, collapse = " + "))

  y <- data[[y_var]]
  x <- data[[x_var]]

  # Remove missing values
  vars_needed <- c(y_var, x_var, controls)
  complete_idx <- complete.cases(data[, vars_needed])
  data_clean <- data[complete_idx, ]
  y <- data_clean[[y_var]]
  x <- data_clean[[x_var]]
  n <- nrow(data_clean)

  # Evaluation point: sample means
  x_mean <- mean(x, na.rm = TRUE)

  # Default thresholds: quantiles of y
  if (is.null(thresholds)) {
    thresholds <- quantile(y, probs = seq(0.05, 0.95, length.out = n_thresholds), na.rm = TRUE)
    thresholds <- unique(thresholds)
  }

  results <- data.frame(
    threshold = numeric(),
    coefficient = numeric(),
    marginal_effect = numeric(),
    me_lower = numeric(),
    me_upper = numeric(),
    prop_above = numeric()
  )

  for (tau in thresholds) {
    # Binary outcome: 1 if y > tau
    data_clean$y_binary <- as.integer(data_clean[[y_var]] > tau)

    # Skip if all same value
    if (length(unique(data_clean$y_binary)) < 2) next

    # Logistic regression with controls
    tryCatch({
      model <- glm(as.formula(formula_str), data = data_clean,
                   family = binomial(link = "logit"))
      coefs <- coef(model)

      if (any(is.na(coefs)) || !(x_var %in% names(coefs))) next

      # Marginal effect at sample mean for rf_fact_t07
      # Need to compute linear predictor at mean values
      newdata_mean <- data.frame(lapply(data_clean[, vars_needed[-1], drop = FALSE],
                                         function(col) {
                                           if (is.numeric(col)) mean(col, na.rm = TRUE)
                                           else names(which.max(table(col)))
                                         }))

      # For factor variables, use the reference level prediction
      linear_pred <- predict(model, newdata = newdata_mean, type = "link")
      lambda_val <- plogis(linear_pred)
      beta_rf <- coefs[x_var]
      marginal_effect <- beta_rf * lambda_val * (1 - lambda_val)

      # Bootstrap for confidence intervals
      boot_me <- numeric(n_bootstrap)
      for (b in 1:n_bootstrap) {
        weights <- rexp(n, rate = 1)

        tryCatch({
          boot_fit <- glm(as.formula(formula_str), data = data_clean,
                          family = binomial(link = "logit"), weights = weights)
          boot_coefs <- coef(boot_fit)
          if (!any(is.na(boot_coefs)) && x_var %in% names(boot_coefs)) {
            boot_lp <- predict(boot_fit, newdata = newdata_mean, type = "link")
            boot_lambda <- plogis(boot_lp)
            boot_me[b] <- boot_coefs[x_var] * boot_lambda * (1 - boot_lambda)
          } else {
            boot_me[b] <- NA
          }
        }, error = function(e) {
          boot_me[b] <- NA
        })
      }

      # Calculate bootstrap CI
      boot_me_clean <- boot_me[!is.na(boot_me)]
      if (length(boot_me_clean) > 10) {
        me_lower <- quantile(boot_me_clean, 0.025)
        me_upper <- quantile(boot_me_clean, 0.975)
      } else {
        me_lower <- NA
        me_upper <- NA
      }

      results <- rbind(results, data.frame(
        threshold = tau,
        coefficient = beta_rf,
        marginal_effect = marginal_effect,
        me_lower = me_lower,
        me_upper = me_upper,
        prop_above = mean(data_clean$y_binary, na.rm = TRUE)
      ))

    }, error = function(e) {
      # Skip this threshold on error
    })
  }

  return(results)
}
```

### Full Sample with Controls

```{r}
#| label: dist-reg-full-controls
#| fig-cap: "Distribution Regression with Controls (Full Sample)"
#| warning: false

# Define control variables (excluding ff12 which is a factor - handle separately)
# For simplicity, we'll use the numeric controls and ff12 as factor
controls <- c("log_assets", "log_proceeds", "roll_vwretd", "ff12")

dr_full_ctrl <- distribution_regression_controls(
  df_complete, "rf_fact_t07", "first_day_return",
  controls, n_thresholds = 25, n_bootstrap = 200
)

ggplot(dr_full_ctrl, aes(x = threshold, y = marginal_effect)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper),
              alpha = 0.2, fill = "darkgreen") +
  geom_line(color = "darkgreen", linewidth = 1) +
  geom_point(color = "darkgreen", size = 2) +
  labs(
    title = "Distribution Regression with Controls: Full Sample",
    subtitle = "Controlling for log(assets), log(proceeds), roll_vwretd, and FF12 industry FE",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### Comparison: Baseline vs. Controlled Distribution Regression

```{r}
#| label: dist-reg-comparison
#| fig-cap: "Distribution Regression: Baseline vs. With Controls"
#| fig-height: 6

# Add labels
dr_full$specification <- "Baseline"
dr_full_ctrl$specification <- "With Controls"

dr_compare <- rbind(
  dr_full[, c("threshold", "marginal_effect", "me_lower", "me_upper", "specification")],
  dr_full_ctrl[, c("threshold", "marginal_effect", "me_lower", "me_upper", "specification")]
)

ggplot(dr_compare, aes(x = threshold, y = marginal_effect,
                        color = specification, fill = specification)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper), alpha = 0.15, color = NA) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("Baseline" = "steelblue", "With Controls" = "darkgreen")) +
  scale_fill_manual(values = c("Baseline" = "steelblue", "With Controls" = "darkgreen")) +
  labs(
    title = "Distribution Regression: Effect of Adding Controls",
    subtitle = "Full sample | Marginal effect of rf_fact_t07 on P(Return > threshold)",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact",
    color = "Specification",
    fill = "Specification"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )
```

### Pre vs. Post-Omnicare with Controls

```{r}
#| label: dist-reg-periods-controls
#| fig-cap: "Distribution Regression by Period (With Controls)"
#| warning: false

dr_pre_ctrl <- distribution_regression_controls(
  df_complete[!df_complete$post_omnicare, ],
  "rf_fact_t07", "first_day_return",
  controls, n_thresholds = 20, n_bootstrap = 200
)

dr_post_ctrl <- distribution_regression_controls(
  df_complete[df_complete$post_omnicare, ],
  "rf_fact_t07", "first_day_return",
  controls, n_thresholds = 25, n_bootstrap = 200
)

dr_pre_ctrl$period <- "Pre-Omnicare"
dr_post_ctrl$period <- "Post-Omnicare"
dr_periods_ctrl <- rbind(dr_pre_ctrl, dr_post_ctrl)

ggplot(dr_periods_ctrl, aes(x = threshold, y = marginal_effect,
                             color = period, fill = period)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_ribbon(aes(ymin = me_lower, ymax = me_upper), alpha = 0.15, color = NA) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  scale_fill_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  labs(
    title = "Distribution Regression: Pre vs. Post-Omnicare (With Controls)",
    subtitle = "Controlling for log(assets), log(proceeds), roll_vwretd, and FF12 industry FE",
    x = "First-Day Return Threshold",
    y = "Marginal Effect ∂P/∂rf_fact",
    color = "Period",
    fill = "Period"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )
```

### 5.4 Summary of Covariate Analysis

```{r}
#| label: covariate-summary

cat("=== COVARIATE-CONTROLLED ANALYSIS SUMMARY ===\n\n")

cat("Controls included:\n")
cat("  - log(assets_thous): Firm size proxy\n")
cat("  - log(total_proceeds_thous): Deal size\n")
cat("  - roll_vwretd: Market conditions (30-day rolling VW return)\n")
cat("  - ff12: Fama-French 12 industry fixed effects\n\n")

cat("Sample sizes:\n")
cat("  - Full sample (complete cases):", nrow(df_complete), "\n")
cat("  - Pre-Omnicare:", sum(!df_complete$post_omnicare), "\n")
cat("  - Post-Omnicare:", sum(df_complete$post_omnicare), "\n\n")

cat("Key findings:\n")
baseline_coef <- coef(model_full)[2]
controlled_coef <- coef(model_full_ctrl)["rf_fact_t07"]
cat(sprintf("  - Baseline rf_fact_t07 coefficient: %.4f\n", baseline_coef))
cat(sprintf("  - Controlled rf_fact_t07 coefficient: %.4f\n", controlled_coef))
cat(sprintf("  - Change: %.4f (%.1f%%)\n",
            controlled_coef - baseline_coef,
            100 * (controlled_coef - baseline_coef) / abs(baseline_coef)))

if (sign(baseline_coef) == sign(controlled_coef)) {
  cat("\nThe sign of the rf_fact_t07 effect is ROBUST to the inclusion of controls.\n")
} else {
  cat("\nWARNING: The sign of the rf_fact_t07 effect CHANGES with the inclusion of controls.\n")
}
```

---

## 6. CFM Distributional Decomposition

This section implements the counterfactual decomposition from [Chernozhukov, Fernandez-Val, and Melly (2013)](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA10582). We decompose the change in the distribution of first-day returns between pre- and post-Omnicare periods into:

1. **Structure Effect**: Changes due to differences in how the market prices IPOs for a given level of fact-intensity (the "wage structure" in CFM terminology)
2. **Composition Effect**: Changes due to differences in the distribution of fact-intensity itself

### Notation and Setup

Let $Y_j$ denote first-day returns and $X_j$ denote fact-intensity for period $j \in \{0, 1\}$ (pre/post Omnicare).

- $F_{Y\langle 0|0 \rangle}$: Observed pre-Omnicare return distribution
- $F_{Y\langle 1|1 \rangle}$: Observed post-Omnicare return distribution
- $F_{Y\langle 0|1 \rangle}$: **Counterfactual** - returns that would have prevailed post-Omnicare if the market still priced like pre-Omnicare

The decomposition is:
$$F_{Y\langle 1|1 \rangle} - F_{Y\langle 0|0 \rangle} = \underbrace{\left[F_{Y\langle 1|1 \rangle} - F_{Y\langle 0|1 \rangle}\right]}_{\text{Structure Effect}} + \underbrace{\left[F_{Y\langle 0|1 \rangle} - F_{Y\langle 0|0 \rangle}\right]}_{\text{Composition Effect}}$$

### Raw Distributional Shifts: Pre vs. Post Omnicare

Before running the decomposition, let's visualize how both the covariate (rf_fact) and the outcome (first_day_return) actually shifted between periods. This helps us interpret the composition and structure effects.

```{r}
#| label: raw-distribution-shifts
#| fig-cap: "Raw Distributional Shifts: Pre vs. Post Omnicare"
#| fig-height: 8

library(patchwork)

# Prepare data
df_pre_raw <- df[!df$post_omnicare, ]
df_post_raw <- df[df$post_omnicare, ]

# Panel A: rf_fact distribution (what drives composition effect)
p_rf_cdf <- ggplot() +
  stat_ecdf(data = df_pre_raw, aes(x = rf_fact_t07, color = "Pre-Omnicare"), linewidth = 1.2) +
  stat_ecdf(data = df_post_raw, aes(x = rf_fact_t07, color = "Post-Omnicare"), linewidth = 1.2) +
  scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  labs(
    title = "A. Covariate Distribution: Fact-Intensity (rf_fact_t07)",
    subtitle = "This drives the COMPOSITION effect",
    x = "Fact-Intensity (rf_fact_t07)",
    y = "Cumulative Probability",
    color = "Period"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

# Panel B: First-day return distribution (the outcome)
p_return_cdf <- ggplot() +
  stat_ecdf(data = df_pre_raw, aes(x = first_day_return, color = "Pre-Omnicare"), linewidth = 1.2) +
  stat_ecdf(data = df_post_raw, aes(x = first_day_return, color = "Post-Omnicare"), linewidth = 1.2) +
  scale_color_manual(values = c("Pre-Omnicare" = "coral", "Post-Omnicare" = "steelblue")) +
  coord_cartesian(xlim = c(-0.5, 1.5)) +  # Focus on main mass
  labs(
    title = "B. Outcome Distribution: First-Day Returns",
    subtitle = "Total change = Structure + Composition",
    x = "First-Day Return",
    y = "Cumulative Probability",
    color = "Period"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

# Combine
p_rf_cdf / p_return_cdf

# Print summary statistics
cat("=== DISTRIBUTIONAL SHIFT SUMMARY ===\n\n")
cat("Fact-Intensity (rf_fact_t07):\n")
cat(sprintf("  Pre-Omnicare mean:  %.4f\n", mean(df_pre_raw$rf_fact_t07, na.rm = TRUE)))
cat(sprintf("  Post-Omnicare mean: %.4f\n", mean(df_post_raw$rf_fact_t07, na.rm = TRUE)))
cat(sprintf("  Difference: %.4f (%s)\n\n",
            mean(df_post_raw$rf_fact_t07, na.rm = TRUE) - mean(df_pre_raw$rf_fact_t07, na.rm = TRUE),
            ifelse(mean(df_post_raw$rf_fact_t07, na.rm = TRUE) > mean(df_pre_raw$rf_fact_t07, na.rm = TRUE),
                   "MORE facts post-Omnicare", "FEWER facts post-Omnicare")))

cat("First-Day Returns:\n")
cat(sprintf("  Pre-Omnicare mean:  %.4f (%.1f%%)\n", mean(df_pre_raw$first_day_return, na.rm = TRUE),
            100 * mean(df_pre_raw$first_day_return, na.rm = TRUE)))
cat(sprintf("  Post-Omnicare mean: %.4f (%.1f%%)\n", mean(df_post_raw$first_day_return, na.rm = TRUE),
            100 * mean(df_post_raw$first_day_return, na.rm = TRUE)))
cat(sprintf("  Difference: %.4f (%s)\n",
            mean(df_post_raw$first_day_return, na.rm = TRUE) - mean(df_pre_raw$first_day_return, na.rm = TRUE),
            ifelse(mean(df_post_raw$first_day_return, na.rm = TRUE) < mean(df_pre_raw$first_day_return, na.rm = TRUE),
                   "LESS underpricing post-Omnicare", "MORE underpricing post-Omnicare")))
```

```{r}
#| label: cfm-functions
#| warning: false

# Function to estimate conditional distribution using logit regression
estimate_conditional_distribution <- function(data, outcome_var, covariate, y_grid = NULL) {

  if (is.null(y_grid)) {
    y_values <- data[[outcome_var]]
    y_grid <- quantile(y_values, probs = seq(0.05, 0.95, by = 0.05), na.rm = TRUE)
    y_grid <- unique(y_grid)
  }

  distribution_results <- list()
  successful_fits <- c()

  for (j in seq_along(y_grid)) {
    y_threshold <- y_grid[j]

    temp_data <- data
    temp_data$binary_indicator <- as.numeric(data[[outcome_var]] <= y_threshold)

    prop_below <- mean(temp_data$binary_indicator)
    if (prop_below == 0 || prop_below == 1) next

    tryCatch({
      logit_formula <- as.formula(paste("binary_indicator ~", covariate))
      logit_fit <- glm(logit_formula, family = binomial(link = "logit"), data = temp_data)

      if (!logit_fit$converged) next

      distribution_results[[length(distribution_results) + 1]] <- list(
        y_threshold = y_threshold,
        fit = logit_fit,
        coefficients = coef(logit_fit)
      )

      successful_fits <- c(successful_fits, y_threshold)

    }, error = function(e) {
      # Silent error handling
    })
  }

  return(list(
    distribution_results = distribution_results,
    y_grid = successful_fits
  ))
}

# Function to predict conditional CDF given covariates and estimated models
predict_conditional_cdf <- function(distribution_results, covariate_values, y_grid) {

  n_obs <- length(covariate_values)
  n_thresholds <- length(y_grid)

  cdf_matrix <- matrix(NA, nrow = n_obs, ncol = n_thresholds)

  actual_thresholds <- sapply(distribution_results, function(x) x$y_threshold)

  for (i in 1:n_thresholds) {
    match_idx <- which(abs(actual_thresholds - y_grid[i]) < 1e-10)

    if (length(match_idx) == 1) {
      coefs <- distribution_results[[match_idx]]$coefficients
      if (length(coefs) >= 2) {
        linear_pred <- coefs[1] + coefs[2] * covariate_values
        cdf_matrix[, i] <- plogis(linear_pred)
      }
    }
  }

  return(cdf_matrix)
}

# Function to estimate marginal CDF from conditional CDF
estimate_marginal_cdf <- function(conditional_cdf_matrix, y_grid) {
  marginal_cdf <- colMeans(conditional_cdf_matrix, na.rm = TRUE)

  return(data.frame(
    y_threshold = y_grid,
    cdf_value = marginal_cdf
  ))
}

# Main CFM decomposition function
cfm_decomposition <- function(data, outcome_var, covariate, group_var, y_grid = NULL) {

  # Split data by groups
  before_data <- data[data[[group_var]] == FALSE & !is.na(data[[outcome_var]]) & !is.na(data[[covariate]]), ]
  after_data <- data[data[[group_var]] == TRUE & !is.na(data[[outcome_var]]) & !is.na(data[[covariate]]), ]

  # Create common y_grid based on combined data
  if (is.null(y_grid)) {
    all_outcome_values <- c(before_data[[outcome_var]], after_data[[outcome_var]])
    y_grid <- quantile(all_outcome_values, probs = seq(0.05, 0.95, by = 0.05), na.rm = TRUE)
    y_grid <- unique(y_grid)
  }

  # Estimate conditional distributions for each period
  cond_dist_before <- estimate_conditional_distribution(before_data, outcome_var, covariate, y_grid)
  cond_dist_after <- estimate_conditional_distribution(after_data, outcome_var, covariate, y_grid)

  # Use intersection of successful fits
  common_y_grid <- intersect(cond_dist_before$y_grid, cond_dist_after$y_grid)

  if (length(common_y_grid) < 5) {
    stop(paste("Insufficient common thresholds for decomposition. Only", length(common_y_grid), "available."))
  }

  # Find indices of common thresholds
  before_indices <- match(common_y_grid, cond_dist_before$y_grid)
  after_indices <- match(common_y_grid, cond_dist_after$y_grid)

  valid_indices <- !is.na(before_indices) & !is.na(after_indices)
  common_y_grid <- common_y_grid[valid_indices]
  before_indices <- before_indices[valid_indices]
  after_indices <- after_indices[valid_indices]

  # Extract results for common grid
  before_results <- cond_dist_before$distribution_results[before_indices]
  after_results <- cond_dist_after$distribution_results[after_indices]

  # Extract covariate values
  X_before <- before_data[[covariate]]
  X_after <- after_data[[covariate]]

  # Calculate the four distributions:

  # 1. F^{before|before}: Observed before distribution
  cdf_before_given_before <- predict_conditional_cdf(before_results, X_before, common_y_grid)
  F_before_before <- estimate_marginal_cdf(cdf_before_given_before, common_y_grid)

  # 2. F^{after|after}: Observed after distribution
  cdf_after_given_after <- predict_conditional_cdf(after_results, X_after, common_y_grid)
  F_after_after <- estimate_marginal_cdf(cdf_after_given_after, common_y_grid)

  # 3. F^{before|after}: Counterfactual - before structure with after composition
  cdf_before_given_after <- predict_conditional_cdf(before_results, X_after, common_y_grid)
  F_before_after <- estimate_marginal_cdf(cdf_before_given_after, common_y_grid)

  # 4. F^{after|before}: Counterfactual - after structure with before composition
  cdf_after_given_before <- predict_conditional_cdf(after_results, X_before, common_y_grid)
  F_after_before <- estimate_marginal_cdf(cdf_after_given_before, common_y_grid)

  # Decomposition
  total_change <- F_after_after$cdf_value - F_before_before$cdf_value
  structure_effect <- F_after_after$cdf_value - F_before_after$cdf_value
  composition_effect <- F_before_after$cdf_value - F_before_before$cdf_value

  # Alternative decomposition
  structure_effect_alt <- F_after_before$cdf_value - F_before_before$cdf_value
  composition_effect_alt <- F_after_after$cdf_value - F_after_before$cdf_value

  decomposition_results <- data.frame(
    y_threshold = common_y_grid,
    F_before_before = F_before_before$cdf_value,
    F_after_after = F_after_after$cdf_value,
    F_before_after = F_before_after$cdf_value,
    F_after_before = F_after_before$cdf_value,
    total_change = total_change,
    structure_effect = structure_effect,
    composition_effect = composition_effect,
    structure_effect_alt = structure_effect_alt,
    composition_effect_alt = composition_effect_alt
  )

  return(list(
    decomposition = decomposition_results,
    sample_sizes = list(before = nrow(before_data), after = nrow(after_data)),
    y_grid = common_y_grid
  ))
}

# Bootstrap function for confidence intervals
bootstrap_cfm_decomposition <- function(data, outcome_var, covariate, group_var,
                                         y_grid = NULL, n_bootstrap = 200) {

  # Original decomposition
  original_results <- cfm_decomposition(data, outcome_var, covariate, group_var, y_grid)
  y_grid_common <- original_results$y_grid

  # Bootstrap
  bootstrap_results <- list()

  for (b in 1:n_bootstrap) {
    tryCatch({
      # Sample with replacement within each group
      before_data <- data[data[[group_var]] == FALSE & !is.na(data[[outcome_var]]) & !is.na(data[[covariate]]), ]
      after_data <- data[data[[group_var]] == TRUE & !is.na(data[[outcome_var]]) & !is.na(data[[covariate]]), ]

      before_boot <- before_data[sample(nrow(before_data), replace = TRUE), ]
      after_boot <- after_data[sample(nrow(after_data), replace = TRUE), ]

      boot_data <- rbind(before_boot, after_boot)

      boot_results <- cfm_decomposition(boot_data, outcome_var, covariate, group_var, y_grid_common)
      bootstrap_results[[b]] <- boot_results$decomposition

    }, error = function(e) {
      # Silent error handling
    })
  }

  # Remove failed bootstrap iterations
  bootstrap_results <- bootstrap_results[!sapply(bootstrap_results, is.null)]

  if (length(bootstrap_results) > 10) {
    n_successful <- length(bootstrap_results)
    n_thresholds <- length(y_grid_common)

    # Extract bootstrap values
    total_change_boot <- matrix(NA, n_successful, n_thresholds)
    structure_boot <- matrix(NA, n_successful, n_thresholds)
    composition_boot <- matrix(NA, n_successful, n_thresholds)

    for (i in 1:n_successful) {
      if (nrow(bootstrap_results[[i]]) == n_thresholds) {
        total_change_boot[i, ] <- bootstrap_results[[i]]$total_change
        structure_boot[i, ] <- bootstrap_results[[i]]$structure_effect
        composition_boot[i, ] <- bootstrap_results[[i]]$composition_effect
      }
    }

    # Calculate confidence intervals
    original_results$decomposition$total_ci_lower <- apply(total_change_boot, 2, quantile, 0.025, na.rm = TRUE)
    original_results$decomposition$total_ci_upper <- apply(total_change_boot, 2, quantile, 0.975, na.rm = TRUE)
    original_results$decomposition$structure_ci_lower <- apply(structure_boot, 2, quantile, 0.025, na.rm = TRUE)
    original_results$decomposition$structure_ci_upper <- apply(structure_boot, 2, quantile, 0.975, na.rm = TRUE)
    original_results$decomposition$composition_ci_lower <- apply(composition_boot, 2, quantile, 0.025, na.rm = TRUE)
    original_results$decomposition$composition_ci_upper <- apply(composition_boot, 2, quantile, 0.975, na.rm = TRUE)
  }

  return(original_results)
}
```

### Run the Decomposition

```{r}
#| label: cfm-run
#| warning: false
#| fig-height: 10

# Run CFM decomposition with bootstrap
decomp_results <- bootstrap_cfm_decomposition(
  data = df,
  outcome_var = "first_day_return",
  covariate = "rf_fact_t07",
  group_var = "post_omnicare",
  n_bootstrap = 500
)

decomp_data <- decomp_results$decomposition

cat("=== CFM DECOMPOSITION SUMMARY ===\n\n")
cat("Sample sizes:\n")
cat("  Pre-Omnicare:", decomp_results$sample_sizes$before, "\n")
cat("  Post-Omnicare:", decomp_results$sample_sizes$after, "\n")
cat("  Number of thresholds:", length(decomp_results$y_grid), "\n\n")

# Average effects across distribution
cat("Average effects across the distribution:\n")
cat(sprintf("  Total change: %.4f\n", mean(decomp_data$total_change)))
cat(sprintf("  Structure effect: %.4f\n", mean(decomp_data$structure_effect)))
cat(sprintf("  Composition effect: %.4f\n", mean(decomp_data$composition_effect)))
```

### Plot: All Four Distributions

```{r}
#| label: cfm-distributions
#| fig-cap: "Observed and Counterfactual CDFs"
#| fig-height: 6

# Reshape for plotting
dist_long <- decomp_data |>
  dplyr::select(y_threshold, F_before_before, F_after_after, F_before_after, F_after_before) |>
  tidyr::pivot_longer(cols = -y_threshold, names_to = "distribution", values_to = "cdf_value") |>
  dplyr::mutate(
    dist_label = dplyr::case_when(
      distribution == "F_before_before" ~ "Observed Pre-Omnicare",
      distribution == "F_after_after" ~ "Observed Post-Omnicare",
      distribution == "F_before_after" ~ "Pre Structure + Post Composition",
      distribution == "F_after_before" ~ "Post Structure + Pre Composition"
    ),
    dist_type = dplyr::case_when(
      distribution %in% c("F_before_before", "F_after_after") ~ "Observed",
      TRUE ~ "Counterfactual"
    )
  )

ggplot(dist_long, aes(x = y_threshold, y = cdf_value, color = dist_label, linetype = dist_type)) +
  geom_line(linewidth = 1.1) +
  scale_linetype_manual(values = c("Observed" = "solid", "Counterfactual" = "dashed")) +
  scale_color_manual(values = c(
    "Observed Pre-Omnicare" = "coral",
    "Observed Post-Omnicare" = "steelblue",
    "Pre Structure + Post Composition" = "darkgreen",
    "Post Structure + Pre Composition" = "purple"
  )) +
  labs(
    title = "CFM Decomposition: Observed and Counterfactual CDFs",
    subtitle = "First-day return distributions pre vs. post Omnicare",
    x = "First-Day Return",
    y = "Cumulative Probability F(return)",
    color = "Distribution",
    linetype = "Type"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "bottom"
  ) +
  guides(color = guide_legend(nrow = 2))
```

### Plot: Decomposition Effects

```{r}
#| label: cfm-effects
#| fig-cap: "CFM Decomposition: Structure vs. Composition Effects"
#| fig-height: 6

# Reshape effects for plotting
effect_long <- decomp_data |>
  dplyr::select(y_threshold, total_change, structure_effect, composition_effect) |>
  tidyr::pivot_longer(cols = -y_threshold, names_to = "effect_type", values_to = "effect_value") |>
  dplyr::mutate(
    effect_label = dplyr::case_when(
      effect_type == "total_change" ~ "Total Change",
      effect_type == "structure_effect" ~ "Structure Effect (Pricing)",
      effect_type == "composition_effect" ~ "Composition Effect (rf_fact distribution)"
    )
  )

# Check if we have confidence intervals
has_ci <- "total_ci_lower" %in% names(decomp_data)

if (has_ci) {
  ggplot() +
    # Confidence ribbons
    geom_ribbon(data = decomp_data,
                aes(x = y_threshold, ymin = total_ci_lower, ymax = total_ci_upper),
                fill = "black", alpha = 0.15) +
    geom_ribbon(data = decomp_data,
                aes(x = y_threshold, ymin = structure_ci_lower, ymax = structure_ci_upper),
                fill = "red", alpha = 0.15) +
    geom_ribbon(data = decomp_data,
                aes(x = y_threshold, ymin = composition_ci_lower, ymax = composition_ci_upper),
                fill = "blue", alpha = 0.15) +
    # Effect lines
    geom_line(data = effect_long,
              aes(x = y_threshold, y = effect_value, color = effect_label),
              linewidth = 1.2) +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
    scale_color_manual(values = c(
      "Total Change" = "black",
      "Structure Effect (Pricing)" = "red",
      "Composition Effect (rf_fact distribution)" = "blue"
    )) +
    labs(
      title = "CFM Decomposition: Structure vs. Composition Effects",
      subtitle = "Total change = Structure effect + Composition effect",
      x = "First-Day Return Threshold",
      y = "Change in Cumulative Probability",
      color = "Effect Type",
      caption = "Shaded areas: 95% bootstrap confidence intervals"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      legend.position = "bottom"
    )
} else {
  ggplot(effect_long, aes(x = y_threshold, y = effect_value, color = effect_label)) +
    geom_line(linewidth = 1.2) +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
    scale_color_manual(values = c(
      "Total Change" = "black",
      "Structure Effect (Pricing)" = "red",
      "Composition Effect (rf_fact distribution)" = "blue"
    )) +
    labs(
      title = "CFM Decomposition: Structure vs. Composition Effects",
      subtitle = "Total change = Structure effect + Composition effect",
      x = "First-Day Return Threshold",
      y = "Change in Cumulative Probability",
      color = "Effect Type"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14),
      legend.position = "bottom"
    )
}
```

### Interpretation

```{r}
#| label: cfm-interpretation

cat("=== INTERPRETATION ===\n\n")

avg_total <- mean(decomp_data$total_change)
avg_structure <- mean(decomp_data$structure_effect)
avg_composition <- mean(decomp_data$composition_effect)

if (avg_total > 0) {
  cat("TOTAL CHANGE: Post-Omnicare has MORE mass at lower returns (less underpricing overall).\n")
} else {
  cat("TOTAL CHANGE: Post-Omnicare has LESS mass at lower returns (more underpricing overall).\n")
}

cat("\nDECOMPOSITION:\n")

# Structure effect interpretation
if (avg_structure > 0) {
  cat("- STRUCTURE EFFECT (", round(avg_structure, 4), "): The market PRICES IPOs differently post-Omnicare.\n")
  cat("  For the same level of fact-intensity, post-Omnicare IPOs have LESS underpricing.\n")
  cat("  This suggests the market reacted to Omnicare by requiring less 'money on the table.'\n")
} else {
  cat("- STRUCTURE EFFECT (", round(avg_structure, 4), "): The market PRICES IPOs differently post-Omnicare.\n")
  cat("  For the same level of fact-intensity, post-Omnicare IPOs have MORE underpricing.\n")
}

# Composition effect interpretation - use actual data to determine direction
rf_pre_mean <- mean(df[!df$post_omnicare, "rf_fact_t07"], na.rm = TRUE)
rf_post_mean <- mean(df[df$post_omnicare, "rf_fact_t07"], na.rm = TRUE)
rf_shift_direction <- ifelse(rf_post_mean > rf_pre_mean, "increased (more facts)", "decreased (fewer facts)")

if (avg_composition > 0) {
  cat("\n- COMPOSITION EFFECT (", round(avg_composition, 4), "): The distribution of rf_fact SHIFTED post-Omnicare.\n")
  cat("  Given the same pricing structure, changes in fact-intensity would have led to LESS underpricing.\n")
} else {
  cat("\n- COMPOSITION EFFECT (", round(avg_composition, 4), "): The distribution of rf_fact SHIFTED post-Omnicare.\n")
  cat("  Given the same pricing structure, changes in fact-intensity would have led to MORE underpricing.\n")
}
cat(sprintf("  Fact: rf_fact %s post-Omnicare (pre mean: %.4f, post mean: %.4f)\n",
            rf_shift_direction, rf_pre_mean, rf_post_mean))

# Relative contributions
total_abs <- abs(avg_structure) + abs(avg_composition)
if (total_abs > 0) {
  cat(sprintf("\nRELATIVE CONTRIBUTIONS:\n"))
  cat(sprintf("  Structure effect: %.1f%% of total absolute change\n", 100 * abs(avg_structure) / total_abs))
  cat(sprintf("  Composition effect: %.1f%% of total absolute change\n", 100 * abs(avg_composition) / total_abs))
}
```

### Technical Notes on CFM Decomposition

The decomposition follows Chernozhukov, Fernandez-Val, and Melly (2013, *Econometrica*).

**Key insight**: The total change in the distribution can be attributed to two sources:

1. **Structure Effect** ($F_{Y\langle 1|1 \rangle} - F_{Y\langle 0|1 \rangle}$): How the conditional distribution $F_{Y|X}$ changed. This captures changes in how the market translates fact-intensity into returns.

2. **Composition Effect** ($F_{Y\langle 0|1 \rangle} - F_{Y\langle 0|0 \rangle}$): How the distribution of $X$ (fact-intensity) changed. This captures changes in firm disclosure behavior.

**Estimation**: We estimate $F_{Y|X}(y|x)$ via logistic regressions at each threshold $y$:
$$P(Y \leq y | X = x) = \Lambda(\alpha_y + \beta_y x)$$

The counterfactual $F_{Y\langle 0|1 \rangle}$ is constructed by applying the pre-Omnicare conditional distribution to the post-Omnicare covariate distribution:
$$F_{Y\langle 0|1 \rangle}(y) = \frac{1}{n_1} \sum_{i: \text{post}} F_{Y|X}^{\text{pre}}(y | X_i)$$

Reference: Chernozhukov, V., Fernández-Val, I., & Melly, B. (2013). "Inference on Counterfactual Distributions." *Econometrica*, 81(6), 2205-2268.
